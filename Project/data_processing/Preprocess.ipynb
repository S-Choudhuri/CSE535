{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kuntal',\n",
       " 'Kuntal_eating.txt',\n",
       " 'Pratyay_eating.txt',\n",
       " 'Pratyay.zip',\n",
       " 'Kuntal.zip',\n",
       " 'Pratyay']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x7fb219cdc990>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kuntal', 'Pratyay']\n",
      "../data/Kuntal\n",
      "../data/Pratyay\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "emgFiles = []\n",
    "imuFiles = []\n",
    "annotationFiles = []\n",
    "\n",
    "\n",
    "\n",
    "for root, subdir, files in os.walk(path):\n",
    "    #print (root, subdir, files)\n",
    "    if subdir:\n",
    "        allSubdir=subdir\n",
    "     \n",
    "print (allSubdir)\n",
    "        \n",
    "for each in allSubdir:\n",
    "    print (os.path.join(path,each))\n",
    "    filePaths = os.path.join(path,each)\n",
    "    for root, subdir, files in os.walk(filePaths):\n",
    "        #print(root, subdir, files)\n",
    "        if \"EMG\" in file:\n",
    "            eachUserEMG.append(os.path.join(root,file))\n",
    "        elif \"IMU\" in file:\n",
    "            eachUserIMU.append(os.path.join(root,file))\n",
    "    emgFiles.append(eachUserEMG)\n",
    "    imuFiles.append(eachUserIMU)\n",
    "        \n",
    "print (len(emgFiles))\n",
    "print (len(imuFiles))\n",
    "\n",
    "\n",
    "for root, subdir, files in os.walk(path):\n",
    "    #print (root, subdir, files)\n",
    "    for eachSubdir in subdir:\n",
    "        if \"eating\" in file:\n",
    "            annotationFiles.append(os.path.join(root,file))\n",
    "print (len(annotationFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotationFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Annotation Files with eating times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Kuntal_eating.txt\n",
      "9\n",
      "1554609000000,1554609180000\n",
      "1554609000000 1554609180000\n",
      "1554619680000,1554621000000\n",
      "1554619680000 1554621000000\n",
      "1554657480000,1554658080000\n",
      "1554657480000 1554658080000\n",
      "1554671820000,1554672600000\n",
      "1554671820000 1554672600000\n",
      "1554684720000,1554686100000\n",
      "1554684720000 1554686100000\n",
      "1554693900000,1554694260000\n",
      "1554693900000 1554694260000\n",
      "1554707460000,1554708600000\n",
      "1554707460000 1554708600000\n",
      "1554713400000,1554713820000\n",
      "1554713400000 1554713820000\n",
      "1554736200000,1554737400000\n",
      "1554736200000 1554737400000\n",
      "../data/Pratyay_eating.txt\n",
      "6\n",
      "1554619680000,1554621000000\n",
      "1554619680000 1554621000000\n",
      "1554657540000,1554658080000\n",
      "1554657540000 1554658080000\n",
      "1554686100000,1554688200000\n",
      "1554686100000 1554688200000\n",
      "1554707460000,1554708600000\n",
      "1554707460000 1554708600000\n",
      "1554744360000,1554744960000\n",
      "1554744360000 1554744960000\n",
      "1554768000000,1554770400000\n",
      "1554768000000 1554770400000\n",
      "[[(1554609000000, 1554609180000), (1554619680000, 1554621000000), (1554657480000, 1554658080000), (1554671820000, 1554672600000), (1554684720000, 1554686100000), (1554693900000, 1554694260000), (1554707460000, 1554708600000), (1554713400000, 1554713820000), (1554736200000, 1554737400000)], [(1554619680000, 1554621000000), (1554657540000, 1554658080000), (1554686100000, 1554688200000), (1554707460000, 1554708600000), (1554744360000, 1554744960000), (1554768000000, 1554770400000)]]\n"
     ]
    }
   ],
   "source": [
    "#Eating Data\n",
    "eatData = []\n",
    "for eachFile in annotationFiles:\n",
    "    eachAnnotation = []\n",
    "    print (eachFile)\n",
    "    with open(eachFile,\"r\") as ff:\n",
    "        data = ff.read().split(\"\\n\")[:-1]\n",
    "        print (len(data))\n",
    "        for eachLine in data:\n",
    "            print(eachLine)\n",
    "            print(int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1]))\n",
    "            eachAnnotation.append((int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1])))\n",
    "    eatData.append(eachAnnotation)\n",
    "print (eatData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "#TODO: Skip the first file which is not eat and take the next to last time\n",
    "eatFile = []\n",
    "nonEatFile = []\n",
    "for eachFile in imuFiles:\n",
    "    #print (os.path.basename(eachFile).split(\"_\")[0])\n",
    "    time = int(os.path.basename(eachFile).split(\"_\")[0])\n",
    "    isEat = False\n",
    "    for (start,end) in eatData:\n",
    "        #print (start,end)\n",
    "        if (time > start) and (time < end):\n",
    "            #print (time,start,end)\n",
    "            isEat = True\n",
    "            eatFile.append(eachFile)\n",
    "    if not isEat:\n",
    "        nonEatFile.append(eachFile)\n",
    "print (len(eatFile))\n",
    "print (len(nonEatFile))\n",
    "numEat = len(eatFile)\n",
    "numNoEat = len(nonEatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(file):\n",
    "    \"\"\" Extract features from each files for eat and non-eat data \"\"\"\n",
    "\n",
    "    data=[]\n",
    "    with open(file,'r') as f:\n",
    "        data = f.read().split(\"\\n\")[:-1]\n",
    "    eachFileEatList = []\n",
    "    for eachLine in data:\n",
    "        #print(eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split())\n",
    "        line = eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split()[8:]\n",
    "        line = [float(l) for l in line]\n",
    "        eachFileEatList.append(line)\n",
    "        #print (line)\n",
    "    #print (len(eachFileEatList))\n",
    "    eachFileEatDf = pd.DataFrame(np.array(eachFileEatList))\n",
    "    #print (eachFileEatDf)\n",
    "    #print (eachFileEatDf.shape)\n",
    "    #print (eachFileEatDf.describe().values.flatten().shape)\n",
    "    X = eachFileEatDf.describe().values.flatten()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of each Eat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/Kuntal/1554657994064_IMU.txt', '../data/Kuntal/1554684794345_IMU.txt', '../data/Kuntal/1554657691820_IMU.txt', '../data/Kuntal/1554620789709_IMU.txt', '../data/Kuntal/1554694155587_IMU.txt', '../data/Kuntal/1554672387679_IMU.txt', '../data/Kuntal/1554707779155_IMU.txt', '../data/Kuntal/1554685996371_IMU.txt', '../data/Kuntal/1554708081477_IMU.txt', '../data/Kuntal/1554620489624_IMU.txt', '../data/Kuntal/1554707476855_IMU.txt', '../data/Kuntal/1554672085621_IMU.txt', '../data/Kuntal/1554620189635_IMU.txt', '../data/Kuntal/1554609132515_IMU.txt', '../data/Kuntal/1554685694374_IMU.txt', '../data/Kuntal/1554685394365_IMU.txt', '../data/Kuntal/1554708383693_IMU.txt', '../data/Kuntal/1554685094448_IMU.txt']\n"
     ]
    }
   ],
   "source": [
    "eatDataX = []\n",
    "for eachFile in eatFile:\n",
    "    features = getFeatures(eachFile)\n",
    "    eatDataX.append(features)\n",
    "#print (len(eatDataX))\n",
    "#print (eatDataX)\n",
    "print (eatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Statistics for non-EatData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/Kuntal/1554744320131_IMU.txt', '../data/Kuntal/1554706555402_IMU.txt', '../data/Kuntal/1554739520003_IMU.txt', '../data/Kuntal/1554743420153_IMU.txt', '../data/Kuntal/1554710499845_IMU.txt', '../data/Kuntal/1554693853398_IMU.txt', '../data/Kuntal/1554772886045_IMU.txt', '../data/Kuntal/1554768657213_IMU.txt', '../data/Kuntal/1554687809515_IMU.txt', '../data/Kuntal/1554750020326_IMU.txt', '../data/Kuntal/1554692040297_IMU.txt', '../data/Kuntal/1554696573000_IMU.txt', '../data/Kuntal/1554763823744_IMU.txt', '../data/Kuntal/1554769261326_IMU.txt', '../data/Kuntal/1554754220408_IMU.txt', '../data/Kuntal/1554771375689_IMU.txt', '../data/Kuntal/1554700501295_IMU.txt', '../data/Kuntal/1554695968676_IMU.txt']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(numNoEat,numEat)\n",
    "nonEatSelected = [nonEatFile[i] for i in idx]\n",
    "print (nonEatSelected)\n",
    "print (len(nonEatSelected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "#TODO: Handle zero  Files for both eat and noneat\n",
    "nonEatDataX =  []\n",
    "for eachFile in nonEatSelected:\n",
    "    features = getFeatures(eachFile)\n",
    "    nonEatDataX.append(features)\n",
    "print (len(nonEatDataX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 24)\n"
     ]
    }
   ],
   "source": [
    "X_eat = np.array(eatDataX)\n",
    "print (X_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 24)\n"
     ]
    }
   ],
   "source": [
    "X_noneat = np.array(nonEatDataX)\n",
    "print (X_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "Y_eat = np.array([1]*X_eat.shape[0])\n",
    "print(Y_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "Y_noneat = np.array([0]*X_noneat.shape[0])\n",
    "print(Y_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 24)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.concatenate((X_eat,X_noneat),axis=0)\n",
    "print(X_data.shape)\n",
    "Y_data = np.concatenate((Y_eat,Y_noneat),axis=0)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30, random_state=42, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(XData, yData, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    kernels = [\"linear\", \"rbf\",\"sigmoid\"]\n",
    "    #kernels = [\"linear\"]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels}\n",
    "    grid_search = GridSearchCV(SVC(cache_size=2000), param_grid, cv=nfolds, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(XData, yData)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   23.3s finished\n",
      "/home/kuntal/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "best_params = svc_param_selection(X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = SVC(gamma=best_params['gamma'], C=best_params['C'], kernel = best_params['kernel'])\n",
    "clf = SVC(gamma=0.001, C=0.1, kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n"
     ]
    }
   ],
   "source": [
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
