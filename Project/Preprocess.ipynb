{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kuntal', 'Kuntal_eating.txt', 'Pratyay']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x7f728637d570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "emgFiles = []\n",
    "imuFiles = []\n",
    "for root, subdir, files in os.walk(path):\n",
    "    #print (root, subdir, files)\n",
    "    for file in files:\n",
    "        #../data/Kuntal/1554675106177_EMG.txt\n",
    "        #print (os.path.join(root,file))\n",
    "        if \"EMG\" in file and \"Kuntal\" in root:\n",
    "            emgFiles.append(os.path.join(root,file))\n",
    "        elif \"IMU\" in file and \"Kuntal\" in root:\n",
    "            imuFiles.append(os.path.join(root,file))\n",
    "            \n",
    "print (len(emgFiles))\n",
    "print (len(imuFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Processing EMG Files - Step:1 Removing Duplication by taking mean 2. Handling same epoch for multiple person\n",
    "# emgData = {}\n",
    "# emgDataEat = {}\n",
    "# fileCount = 0\n",
    "# for eachFile in emgFiles:\n",
    "#     #print (eachFile.split(\"/\")[-2]+\"_\"+os.path.basename(eachFile).split(\"_\")[0])\n",
    "#     fileCount+=1\n",
    "#     if fileCount%10 ==0:\n",
    "#         print (fileCount)\n",
    "#     user = eachFile.split(\"/\")[-2]\n",
    "#     with open(eachFile,'r') as f:\n",
    "#         data = f.read().split(\"\\n\")\n",
    "#         for eachLine in data:\n",
    "#             try:\n",
    "            \n",
    "#                 line = eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split()\n",
    "#                 if not line:\n",
    "#                     continue\n",
    "#                 #print (line)\n",
    "#                 e1 = []\n",
    "#                 if (int(line[0]) > 1554619680000 and int(line[0])<1554621000000):\n",
    "#                     print (int(line[0]))\n",
    "#                     print (line)\n",
    "#                     e1.append([int(eachVal) for eachVal in line[1:]])\n",
    "#                     input(\"wait\")\n",
    "#                 if user+line[0] in emgData.keys() :\n",
    "#                     prev = emgData[user+line[0]]\n",
    "#                     curr = [int(eachVal) for eachVal in line[1:]]\n",
    "#                     new = [k+l/2.0 for k,l in zip(prev,curr)]\n",
    "#                     #print (prev,curr,new)\n",
    "#                     emgData[user+line[0]] = new\n",
    "#                 else:\n",
    "#                     emgData[user+line[0]] = [int(eachVal) for eachVal in line[1:]]\n",
    "            \n",
    "#             except:\n",
    "            \n",
    "#                 print (line)\n",
    "            \n",
    "#             #print (emgData[user+line[0]])\n",
    "#             #input()\n",
    "# #     print (len(data))\n",
    "# #     print (data[0])\n",
    "# print (len(emgData.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1554609000000,1554609180000\n",
      "1554609000000 1554609180000\n",
      "1554619680000,1554621000000\n",
      "1554619680000 1554621000000\n",
      "1554657480000,1554658080000\n",
      "1554657480000 1554658080000\n",
      "1554671820000,1554672600000\n",
      "1554671820000 1554672600000\n",
      "1554684720000,1554686100000\n",
      "1554684720000 1554686100000\n",
      "1554693900000,1554694260000\n",
      "1554693900000 1554694260000\n",
      "1554707460000,1554708600000\n",
      "1554707460000 1554708600000\n",
      "1554713400000,1554713820000\n",
      "1554713400000 1554713820000\n",
      "1554736200000,1554737400000\n",
      "1554736200000 1554737400000\n",
      "[(1554609000000, 1554609180000), (1554619680000, 1554621000000), (1554657480000, 1554658080000), (1554671820000, 1554672600000), (1554684720000, 1554686100000), (1554693900000, 1554694260000), (1554707460000, 1554708600000), (1554713400000, 1554713820000), (1554736200000, 1554737400000)]\n"
     ]
    }
   ],
   "source": [
    "#Eating Data\n",
    "eatData = []\n",
    "with open(\"../data/Kuntal_eating.txt\",\"r\") as ff:\n",
    "    data = ff.read().split(\"\\n\")[:-1]\n",
    "    print (len(data))\n",
    "    for eachLine in data:\n",
    "        print(eachLine)\n",
    "        print(int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1]))\n",
    "        eatData.append((int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1])))\n",
    "print (eatData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emgDataNoEat = {}\n",
    "# emgDataEat = {}\n",
    "# fileCount = 0\n",
    "# for eachFile in emgFiles:\n",
    "#     #print (eachFile.split(\"/\")[-2]+\"_\"+os.path.basename(eachFile).split(\"_\")[0])\n",
    "#     fileCount+=1\n",
    "#     if fileCount%10 ==0:\n",
    "#         print (fileCount)\n",
    "#     user = eachFile.split(\"/\")[-2]\n",
    "#     with open(eachFile,'r') as f:\n",
    "#         data = f.read().split(\"\\n\")\n",
    "#         for eachLine in data:\n",
    "#             try:\n",
    "#                 line = eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split()\n",
    "#                 print (line)\n",
    "#                 if not line:\n",
    "#                     continue\n",
    "#                 time = line[0]\n",
    "#                 for idx in range(len(eatData)):\n",
    "#                     start = eatData[idx][0]\n",
    "#                     end = eatData[idx][1]\n",
    "#                     if (time > start) and (time < end):\n",
    "#                         if idx not in emgDataEat.keys():\n",
    "#                             emgDataEat[idx] = []\n",
    "#                         else:\n",
    "#                             emgDataEat[idx].append(line[1:])\n",
    "#                         break\n",
    "#                 print(emgDataEat[idx])\n",
    "#                 input(\"WAT\")\n",
    "#             except:\n",
    "            \n",
    "#                 print (line)\n",
    "            \n",
    "#             #print (emgData[user+line[0]])\n",
    "#             #input()\n",
    "# #     print (len(data))\n",
    "# #     print (data[0])\n",
    "# print (len(emgData.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "#TODO: Skip the first file which is not eat and take the next to last time\n",
    "eatFile = []\n",
    "nonEatFile = []\n",
    "for eachFile in imuFiles:\n",
    "    #print (os.path.basename(eachFile).split(\"_\")[0])\n",
    "    time = int(os.path.basename(eachFile).split(\"_\")[0])\n",
    "    isEat = False\n",
    "    for (start,end) in eatData:\n",
    "        #print (start,end)\n",
    "        if (time > start) and (time < end):\n",
    "            #print (time,start,end)\n",
    "            isEat = True\n",
    "            eatFile.append(eachFile)\n",
    "    if not isEat:\n",
    "        nonEatFile.append(eachFile)\n",
    "print (len(eatFile))\n",
    "print (len(nonEatFile))\n",
    "numEat = len(eatFile)\n",
    "numNoEat = len(nonEatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(file):\n",
    "    \"\"\" Extract features from each files for eat and non-eat data \"\"\"\n",
    "\n",
    "    with open(file,'r') as f:\n",
    "        data = f.read().split(\"\\n\")[:-1]\n",
    "    eachFileEatList = []\n",
    "    for eachLine in data:\n",
    "        #print(eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split())\n",
    "        line = eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split()[1:]\n",
    "        line = [float(l) for l in line]\n",
    "        eachFileEatList.append(line)\n",
    "        #print (line)\n",
    "    print (len(eachFileEatList))\n",
    "    eachFileEatDf = pd.DataFrame(np.array(eachFileEatList))\n",
    "    #print (eachFileEatDf)\n",
    "    #print (eachFileEatDf.shape)\n",
    "    #print (eachFileEatDf.describe().values.flatten().shape)\n",
    "    X = eachFileEatDf.describe().values.flatten()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of each Eat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15080\n",
      "14965\n",
      "14726\n",
      "29816\n",
      "15066\n",
      "15062\n",
      "15064\n",
      "15051\n",
      "15063\n",
      "29834\n",
      "12464\n",
      "15057\n",
      "28843\n",
      "14688\n",
      "14974\n",
      "14962\n",
      "15059\n",
      "14975\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "eatDataX = []\n",
    "for eachFile in eatFile:\n",
    "    features = getFeatures(eachFile)\n",
    "    eatDataX.append(X)\n",
    "print (len(eatDataX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Statistics for non-EatData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/Kuntal/1554675559543_IMU.txt', '../data/Kuntal/1554610032513_IMU.txt', '../data/Kuntal/1554746120187_IMU.txt', '../data/Kuntal/1554692040297_IMU.txt', '../data/Kuntal/1554759920751_IMU.txt', '../data/Kuntal/1554745220162_IMU.txt', '../data/Kuntal/1554689622787_IMU.txt', '../data/Kuntal/1554537185977_IMU.txt', '../data/Kuntal/1554538385970_IMU.txt', '../data/Kuntal/1554614532721_IMU.txt', '../data/Kuntal/1554671481325_IMU.txt', '../data/Kuntal/1554701709821_IMU.txt', '../data/Kuntal/1554762920872_IMU.txt', '../data/Kuntal/1554691738074_IMU.txt', '../data/Kuntal/1554709290580_IMU.txt', '../data/Kuntal/1554761420766_IMU.txt', '../data/Kuntal/1554750020326_IMU.txt', '../data/Kuntal/1554691133754_IMU.txt', '../data/Kuntal/1554673898061_IMU.txt', '../data/Kuntal/1554687507364_IMU.txt', '../data/Kuntal/1554623204833_IMU.txt', '../data/Kuntal/1554611232613_IMU.txt', '../data/Kuntal/1554771979809_IMU.txt', '../data/Kuntal/1554625019199_IMU.txt', '../data/Kuntal/1554658296249_IMU.txt', '../data/Kuntal/1554747920282_IMU.txt', '../data/Kuntal/1554675559543_IMU.txt', '../data/Kuntal/1554621692805_IMU.txt']\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(numNoEat,numEat+10)\n",
    "nonEatSelected = [nonEatFile[i] for i in idx]\n",
    "print (nonEatSelected)\n",
    "print (len(nonEatSelected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537\n",
      "14963\n",
      "14970\n",
      "15078\n",
      "14978\n",
      "14977\n",
      "15069\n",
      "14959\n",
      "14966\n",
      "14963\n",
      "14771\n",
      "15036\n",
      "14956\n",
      "15065\n",
      "15062\n",
      "14975\n",
      "14969\n",
      "14093\n",
      "15041\n",
      "15057\n",
      "30043\n",
      "14851\n",
      "13575\n",
      "29987\n",
      "14679\n",
      "14956\n",
      "7537\n",
      "30027\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#TODO: Handle zero  Files for both eat and noneat\n",
    "nonEatDataX =  []\n",
    "for eachFile in nonEatSelected:\n",
    "    features = getFeatures(eachFile)\n",
    "    nonEatDataX.append(X)\n",
    "print (len(nonEatDataX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 80)\n"
     ]
    }
   ],
   "source": [
    "X_eat = np.array(eatDataX)\n",
    "print (X_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 80)\n"
     ]
    }
   ],
   "source": [
    "X_noneat = np.array(nonEatDataX)\n",
    "print (X_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "Y_eat = np.array([1]*X_eat.shape[0])\n",
    "print(Y_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28,)\n"
     ]
    }
   ],
   "source": [
    "Y_noneat = np.array([0]*X_noneat.shape[0])\n",
    "print(Y_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 80)\n",
      "(46,)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.concatenate((X_eat,X_noneat),axis=0)\n",
    "print(X_data.shape)\n",
    "Y_data = np.concatenate((Y_eat,Y_noneat),axis=0)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.33, random_state=42, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.0001,0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.0001,0.001, 0.01, 0.1, 1]\n",
    "    kernels = [\"linear\", \"rbf\", \"sigmoid\"]\n",
    "    #kernels = [\"linear\"]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels}\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=nfolds, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:    0.9s finished\n",
      "/home/kuntal/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001, 'gamma': 0.0001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma=0.0001, C=0.0001, kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.25%\n"
     ]
    }
   ],
   "source": [
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
