{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kuntal', 'Kuntal_eating.txt', 'Pratyay']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x7f728637d570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.walk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "emgFiles = []\n",
    "imuFiles = []\n",
    "for root, subdir, files in os.walk(path):\n",
    "    #print (root, subdir, files)\n",
    "    for file in files:\n",
    "        #../data/Kuntal/1554675106177_EMG.txt\n",
    "        #print (os.path.join(root,file))\n",
    "        if \"EMG\" in file and \"Kuntal\" in root:\n",
    "            emgFiles.append(os.path.join(root,file))\n",
    "        elif \"IMU\" in file and \"Kuntal\" in root:\n",
    "            imuFiles.append(os.path.join(root,file))\n",
    "            \n",
    "print (len(emgFiles))\n",
    "print (len(imuFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "1554609000000,1554609180000\n",
      "1554609000000 1554609180000\n",
      "1554619680000,1554621000000\n",
      "1554619680000 1554621000000\n",
      "1554657480000,1554658080000\n",
      "1554657480000 1554658080000\n",
      "1554671820000,1554672600000\n",
      "1554671820000 1554672600000\n",
      "1554684720000,1554686100000\n",
      "1554684720000 1554686100000\n",
      "1554693900000,1554694260000\n",
      "1554693900000 1554694260000\n",
      "1554707460000,1554708600000\n",
      "1554707460000 1554708600000\n",
      "1554713400000,1554713820000\n",
      "1554713400000 1554713820000\n",
      "1554736200000,1554737400000\n",
      "1554736200000 1554737400000\n",
      "[(1554609000000, 1554609180000), (1554619680000, 1554621000000), (1554657480000, 1554658080000), (1554671820000, 1554672600000), (1554684720000, 1554686100000), (1554693900000, 1554694260000), (1554707460000, 1554708600000), (1554713400000, 1554713820000), (1554736200000, 1554737400000)]\n"
     ]
    }
   ],
   "source": [
    "#Eating Data\n",
    "eatData = []\n",
    "with open(\"../data/Kuntal_eating.txt\",\"r\") as ff:\n",
    "    data = ff.read().split(\"\\n\")[:-1]\n",
    "    print (len(data))\n",
    "    for eachLine in data:\n",
    "        print(eachLine)\n",
    "        print(int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1]))\n",
    "        eatData.append((int(eachLine.split(\",\")[0]),int(eachLine.split(\",\")[1])))\n",
    "print (eatData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "#TODO: Skip the first file which is not eat and take the next to last time\n",
    "eatFile = []\n",
    "nonEatFile = []\n",
    "for eachFile in imuFiles:\n",
    "    #print (os.path.basename(eachFile).split(\"_\")[0])\n",
    "    time = int(os.path.basename(eachFile).split(\"_\")[0])\n",
    "    isEat = False\n",
    "    for (start,end) in eatData:\n",
    "        #print (start,end)\n",
    "        if (time > start) and (time < end):\n",
    "            #print (time,start,end)\n",
    "            isEat = True\n",
    "            eatFile.append(eachFile)\n",
    "    if not isEat:\n",
    "        nonEatFile.append(eachFile)\n",
    "print (len(eatFile))\n",
    "print (len(nonEatFile))\n",
    "numEat = len(eatFile)\n",
    "numNoEat = len(nonEatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(file):\n",
    "    \"\"\" Extract features from each files for eat and non-eat data \"\"\"\n",
    "\n",
    "    with open(file,'r') as f:\n",
    "        data = f.read().split(\"\\n\")[:-1]\n",
    "    eachFileEatList = []\n",
    "    for eachLine in data:\n",
    "        #print(eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split())\n",
    "        line = eachLine.replace(\"[\",\"\").replace(\"]\",\"\").replace(\",\",\"\").split()[8:]\n",
    "        line = [float(l) for l in line]\n",
    "        eachFileEatList.append(line)\n",
    "        #print (line)\n",
    "    print (len(eachFileEatList))\n",
    "    eachFileEatDf = pd.DataFrame(np.array(eachFileEatList))\n",
    "    #print (eachFileEatDf)\n",
    "    #print (eachFileEatDf.shape)\n",
    "    #print (eachFileEatDf.describe().values.flatten().shape)\n",
    "    X = eachFileEatDf.describe().values.flatten()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics of each Eat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15080\n",
      "14965\n",
      "14726\n",
      "29816\n",
      "15066\n",
      "15062\n",
      "15064\n",
      "15051\n",
      "15063\n",
      "29834\n",
      "12464\n",
      "15057\n",
      "28843\n",
      "14688\n",
      "14974\n",
      "14962\n",
      "15059\n",
      "14975\n",
      "18\n",
      "['../data/Kuntal/1554657994064_IMU.txt', '../data/Kuntal/1554684794345_IMU.txt', '../data/Kuntal/1554657691820_IMU.txt', '../data/Kuntal/1554620789709_IMU.txt', '../data/Kuntal/1554694155587_IMU.txt', '../data/Kuntal/1554672387679_IMU.txt', '../data/Kuntal/1554707779155_IMU.txt', '../data/Kuntal/1554685996371_IMU.txt', '../data/Kuntal/1554708081477_IMU.txt', '../data/Kuntal/1554620489624_IMU.txt', '../data/Kuntal/1554707476855_IMU.txt', '../data/Kuntal/1554672085621_IMU.txt', '../data/Kuntal/1554620189635_IMU.txt', '../data/Kuntal/1554609132515_IMU.txt', '../data/Kuntal/1554685694374_IMU.txt', '../data/Kuntal/1554685394365_IMU.txt', '../data/Kuntal/1554708383693_IMU.txt', '../data/Kuntal/1554685094448_IMU.txt']\n"
     ]
    }
   ],
   "source": [
    "eatDataX = []\n",
    "for eachFile in eatFile:\n",
    "    features = getFeatures(eachFile)\n",
    "    eatDataX.append(features)\n",
    "print (len(eatDataX))\n",
    "#print (eatDataX)\n",
    "print (eatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Statistics for non-EatData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/Kuntal/1554753620379_IMU.txt', '../data/Kuntal/1554687205192_IMU.txt', '../data/Kuntal/1554624112038_IMU.txt', '../data/Kuntal/1554623507216_IMU.txt', '../data/Kuntal/1554763521611_IMU.txt', '../data/Kuntal/1554699292560_IMU.txt', '../data/Kuntal/1554693248967_IMU.txt', '../data/Kuntal/1554671481325_IMU.txt', '../data/Kuntal/1554613332657_IMU.txt', '../data/Kuntal/1554675408423_IMU.txt', '../data/Kuntal/1554750020326_IMU.txt', '../data/Kuntal/1554622902497_IMU.txt', '../data/Kuntal/1554706857637_IMU.txt', '../data/Kuntal/1554686600784_IMU.txt', '../data/Kuntal/1554767448926_IMU.txt', '../data/Kuntal/1554744920142_IMU.txt', '../data/Kuntal/1554610932553_IMU.txt', '../data/Kuntal/1554747620280_IMU.txt']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(numNoEat,numEat)\n",
    "nonEatSelected = [nonEatFile[i] for i in idx]\n",
    "print (nonEatSelected)\n",
    "print (len(nonEatSelected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14568\n",
      "14755\n",
      "30057\n",
      "30047\n",
      "15001\n",
      "15066\n",
      "15066\n",
      "14771\n",
      "14656\n",
      "15065\n",
      "14969\n",
      "30038\n",
      "8475\n",
      "14954\n",
      "15067\n",
      "14983\n",
      "14971\n",
      "14961\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#TODO: Handle zero  Files for both eat and noneat\n",
    "nonEatDataX =  []\n",
    "for eachFile in nonEatSelected:\n",
    "    features = getFeatures(eachFile)\n",
    "    nonEatDataX.append(features)\n",
    "print (len(nonEatDataX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 24)\n"
     ]
    }
   ],
   "source": [
    "X_eat = np.array(eatDataX)\n",
    "print (X_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 24)\n"
     ]
    }
   ],
   "source": [
    "X_noneat = np.array(nonEatDataX)\n",
    "print (X_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "Y_eat = np.array([1]*X_eat.shape[0])\n",
    "print(Y_eat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "Y_noneat = np.array([0]*X_noneat.shape[0])\n",
    "print(Y_noneat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 24)\n",
      "(36,)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.concatenate((X_eat,X_noneat),axis=0)\n",
    "print(X_data.shape)\n",
    "Y_data = np.concatenate((Y_eat,Y_noneat),axis=0)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.30, random_state=42, shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.45%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    kernels = [\"linear\", \"rbf\", \"poly\",\"sigmoid\"]\n",
    "    #kernels = [\"linear\"]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas, 'kernel' : kernels}\n",
    "    grid_search = GridSearchCV(SVC(cache_size=2000), param_grid, cv=nfolds, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 147 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  3.9min finished\n",
      "/home/kuntal/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "best_params = svc_param_selection(X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma=best_params['gamma'], C=best_params['C'], kernel = best_params['kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.73%\n"
     ]
    }
   ],
   "source": [
    "preds_val = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds_val)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
